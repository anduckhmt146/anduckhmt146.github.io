---
layout: post
title: Artificial Intelligence
date: 2025-10-23
categories: cloud-solution
---

# 1. Secure Chat User Interface for Amazon Bedrock

![](/images/AI/476219636-daa34609-19af-49a9-b5d6-0d70c7e534a3.png)

- AWS Bedrock: [![Watch the video](https://img.youtube.com/vi/nSQrY-uPWLY/0.jpg)](https://www.youtube.com/watch?v=nSQrY-uPWLY)

- AWS Agent Core: [![Watch the video](https://img.youtube.com/vi/usFIb9aEd1U/0.jpg)](https://youtu.be/usFIb9aEd1U?si=Ai01V5sQ9iyEYiU4)

- Build Agents: [![Watch the video](https://img.youtube.com/vi/epWeri7OQi8/0.jpg)](https://youtu.be/epWeri7OQi8?si=JhqPnJ143n73fhXP)

# 2. Automated Management of AWS Capacity Blocks

![](/images/AI/automate_workflow.png)

# 3. Architecture to IaC

![](/images/AI/architectureToCode.png)

# 4. Sensitive data in knowledge base + RBAC in RAG

## 4.1. Ensure PII data when response to user

![](/images/AI/build_sensitive_data_knowledge_base_part1.png)

![](/images/AI/scenario1_part2.png)

## 4.2. Role-based access response to user

![](/images/AI/rbac_knowledge_base.png)


# 5. LLM Training Operations AWS

-  LLM training requires specific hardware capabilities and software configurations - including GPU availability, CUDA drivers, Elastic Fabric Adapter (EFA) for high-performance networking, and NCCL for multi-GPU communication.

How to automates the pre-flight checks that validate:

- GPU hardware is properly detected and accessible

- CUDA drivers are correctly installed and functioning

- EFA networking is configured for distributed training

- NCCL libraries are available for multi-GPU communication

- System resources (CPU, memory, disk) meet training requirements

## 5.1. Steps

1. Administrator deploys AWS CloudFormation template with custom settings for CPU, memory, and disk thresholds, along with email address for Amazon Simple Notification Services (SNS) Topics notifications.

2. AWS CloudFormation template creates Amazon EC2 instances and executes pre-flight checks validating GPU health, CUDA drivers, NCCL testing, EFA connectivity, and CPU/memory/disk performance, while configuring security groups, permissions, CloudWatch agent, and notification channels.

3. Amazon SNS topic sends notifications for any failed pre-flight checks to administrator with specific failure details.

4. User initiates the LLM training job by invoking the Amazon Lambda Input function for fetching the training data stored in Amazon S3.

5. Amazon EC2 instances load data from Amazon S3 bucket and runs the LLM training process.

6. Monitor system health continuously through Amazon CloudWatch by tracking real-time CPU usage against defined thresholds, memory consumption, disk space utilization and I/O performance, network throughput and connectivity status, plus GPU utilization and temperature for ML workloads.

7. Send runtime monitoring alerts through Amazon SNS when operational thresholds are exceeded during training, including specific triggering metrics and current system status in each notification.

8. Amazon Lambda Storage Function stores the queryable training metadata in the Amazon DynamoDB.

## 5.2. Design

![](/images/AI/Ref_Arch_07_10_upload_git.png)